#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIæ™ºèƒ½åˆ†ææœåŠ¡
Flask APIæœåŠ¡å™¨
"""

import json
import time
from datetime import datetime, timedelta
from flask import Flask, request, jsonify
from flask_cors import CORS
import logging
import traceback
from typing import Dict, List, Any

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from ai_client import AIClient, WaterAIAnalyzer, create_ai_client, AIProvider, get_recommended_provider

# å°è¯•å¯¼å…¥é…ç½®æ–‡ä»¶
try:
    import config
    print("âœ… æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶ config.py")
except ImportError:
    print("âš ï¸  æœªæ‰¾åˆ° config.pyï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    print("ğŸ’¡ è¯·å¤åˆ¶ config_example.py ä¸º config.py å¹¶å¡«å…¥çœŸå®çš„APIå¯†é’¥")
    
    # é»˜è®¤é…ç½®
    class config:
        # æ¨èä½¿ç”¨å…è´¹AIæœåŠ¡å•†
        AI_PROVIDER = "baidu"  # é»˜è®¤ä½¿ç”¨ç™¾åº¦åƒå¸†
        BAIDU_API_KEY = "your_baidu_api_key_here"
        BAIDU_SECRET_KEY = "your_baidu_secret_key_here"
        BAIDU_MODEL = "ERNIE-3.5-8K"
        
        # å¤‡é€‰é…ç½®
        ALIBABA_API_KEY = "your_alibaba_api_key_here"
        ALIBABA_MODEL = "qwen-turbo"
        
        # OpenAIé…ç½®ï¼ˆä¸æ¨èï¼Œæˆæœ¬é«˜ï¼‰
        OPENAI_API_KEY = "your_openai_api_key_here"
        OPENAI_MODEL = "gpt-3.5-turbo"
        OPENAI_BASE_URL = "https://api.openai.com/v1"
        
        FLASK_PORT = 5000
        FLASK_DEBUG = True
        AI_ANALYSIS_ENABLED = False  # é»˜è®¤å…³é—­AIåˆ†æ

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# åˆ›å»ºFlaskåº”ç”¨
app = Flask(__name__)
CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚

# å…¨å±€å˜é‡
ai_client = None
ai_analyzer = None

def init_ai_service():
    """åˆå§‹åŒ–AIæœåŠ¡ - è‡ªåŠ¨é€‰æ‹©å¯ç”¨çš„å…è´¹AIæœåŠ¡å•†"""
    global ai_client, ai_analyzer
    
    try:
        if not hasattr(config, 'AI_ANALYSIS_ENABLED') or not config.AI_ANALYSIS_ENABLED:
            logger.warning("AIåˆ†æåŠŸèƒ½å·²ç¦ç”¨")
            return False
        
        # è·å–AIæœåŠ¡å•†ä¼˜å…ˆçº§åˆ—è¡¨
        provider_priority = getattr(config, 'AI_PROVIDER_PRIORITY', ['baidu', 'alibaba', 'local', 'openai'])
        
        # å°è¯•æŒ‰ä¼˜å…ˆçº§åˆå§‹åŒ–AIæœåŠ¡
        for provider in provider_priority:
            try:
                success = _try_init_provider(provider)
                if success:
                    logger.info(f"âœ… AIæœåŠ¡åˆå§‹åŒ–æˆåŠŸï¼Œä½¿ç”¨æœåŠ¡å•†: {provider}")
                    return True
            except Exception as e:
                logger.warning(f"âš ï¸ {provider} æœåŠ¡å•†åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                continue
        
        logger.warning("âš ï¸ æ‰€æœ‰AIæœåŠ¡å•†éƒ½æ— æ³•ä½¿ç”¨ï¼Œå°†æä¾›æ¼”ç¤ºåŠŸèƒ½")
        return False
        
    except Exception as e:
        logger.error(f"âŒ AIæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return False

def _try_init_provider(provider: str) -> bool:
    """å°è¯•åˆå§‹åŒ–æŒ‡å®šçš„AIæœåŠ¡å•†"""
    global ai_client, ai_analyzer
    
    if provider == 'baidu':
        if not _check_baidu_config():
            return False
        ai_client = create_ai_client(
            provider="baidu",
            api_key=config.BAIDU_API_KEY,
            secret_key=config.BAIDU_SECRET_KEY,
            model=config.BAIDU_MODEL,
            app_id=getattr(config, 'BAIDU_APP_ID', ''),
            use_iam=getattr(config, 'BAIDU_USE_IAM', False),
            base_url=getattr(config, 'BAIDU_BASE_URL', '')
        )
        
    elif provider == 'alibaba':
        if not _check_alibaba_config():
            return False
        ai_client = create_ai_client(
            provider="alibaba",
            api_key=config.ALIBABA_API_KEY,
            model=config.ALIBABA_MODEL
        )
        
    elif provider == 'local':
        ai_client = create_ai_client(provider="local")
        
    elif provider == 'openai':
        if not _check_openai_config():
            return False
        ai_client = create_ai_client(
            provider="openai",
            api_key=config.OPENAI_API_KEY,
            base_url=config.OPENAI_BASE_URL,
            model=config.OPENAI_MODEL
        )
    else:
        return False
    
    # åˆ›å»ºAIåˆ†æå™¨
    ai_analyzer = WaterAIAnalyzer(ai_client)
    return True

def _check_baidu_config() -> bool:
    """æ£€æŸ¥ç™¾åº¦APIé…ç½®"""
    return (hasattr(config, 'BAIDU_API_KEY') and 
            config.BAIDU_API_KEY != "your_baidu_api_key_here" and
            hasattr(config, 'BAIDU_SECRET_KEY') and
            config.BAIDU_SECRET_KEY != "your_baidu_secret_key_here")

def _check_alibaba_config() -> bool:
    """æ£€æŸ¥é˜¿é‡Œäº‘APIé…ç½®"""
    return (hasattr(config, 'ALIBABA_API_KEY') and 
            config.ALIBABA_API_KEY != "your_alibaba_api_key_here")

def _check_openai_config() -> bool:
    """æ£€æŸ¥OpenAI APIé…ç½®"""
    return (hasattr(config, 'OPENAI_API_KEY') and 
            config.OPENAI_API_KEY != "your_openai_api_key_here")

@app.route('/')
def index():
    """é¦–é¡µ"""
    return jsonify({
        'service': 'AIæ™ºèƒ½åˆ†ææœåŠ¡',
        'version': '1.0.0',
        'status': 'running',
        'ai_enabled': ai_analyzer is not None,
        'endpoints': [
            '/api/ai/analyze/trend',
            '/api/ai/detect/anomaly',
            '/api/ai/generate/report',
            '/api/ai/qa',
            '/api/ai/status'
        ],
        'timestamp': datetime.now().isoformat()
    })

@app.route('/api/ai/status')
def ai_status():
    """AIæœåŠ¡çŠ¶æ€"""
    current_provider = None
    current_model = None
    
    if ai_client:
        current_provider = ai_client.provider.value
        current_model = ai_client.model
    
    return jsonify({
        'ai_enabled': ai_analyzer is not None,
        'provider': current_provider,
        'model': current_model,
        'status': 'ready' if ai_analyzer else 'not_configured',
        'recommended_providers': get_recommended_provider()
    })

@app.route('/api/ai/providers')
def list_providers():
    """è·å–æ”¯æŒçš„AIæœåŠ¡å•†åˆ—è¡¨"""
    return jsonify({
        'success': True,
        'providers': get_recommended_provider(),
        'current_provider': ai_client.provider.value if ai_client else None,
        'message': 'æ¨èä½¿ç”¨å…è´¹é¢åº¦è¾ƒå¤šçš„æœåŠ¡å•†'
    })

@app.route('/api/ai/analyze/trend', methods=['POST'])
def analyze_trend():
    """æ°´ä½è¶‹åŠ¿åˆ†æ"""
    try:
        if not ai_analyzer:
            return jsonify({
                'success': False,
                'error': 'AIæœåŠ¡æœªå¯ç”¨æˆ–é…ç½®é”™è¯¯',
                'message': 'è¯·æ£€æŸ¥APIå¯†é’¥é…ç½®'
            }), 503
            
        data = request.get_json()
        if not data or 'sensor_data' not in data:
            return jsonify({
                'success': False,
                'error': 'ç¼ºå°‘å¿…è¦çš„ä¼ æ„Ÿå™¨æ•°æ®'
            }), 400
        
        sensor_data = data['sensor_data']
        
        # è°ƒç”¨AIåˆ†æ
        result = ai_analyzer.analyze_water_level_trend(sensor_data)
        
        return jsonify({
            'success': result.success,
            'analysis': result.content if result.success else None,
            'provider': result.provider,
            'cost': result.cost,
            'tokens_used': result.tokens_used,
            'response_time': result.response_time,
            'error': result.error_message if not result.success else None,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"è¶‹åŠ¿åˆ†æé”™è¯¯: {str(e)}")
        return jsonify({
            'success': False,
            'error': 'æœåŠ¡å†…éƒ¨é”™è¯¯',
            'message': str(e)
        }), 500

@app.route('/api/ai/detect/anomaly', methods=['POST'])
def detect_anomaly():
    """å¼‚å¸¸æ£€æµ‹åˆ†æ"""
    try:
        if not ai_analyzer:
            return jsonify({
                'success': False,
                'error': 'AIæœåŠ¡æœªå¯ç”¨æˆ–é…ç½®é”™è¯¯'
            }), 503
            
        data = request.get_json()
        if not data or 'current_data' not in data:
            return jsonify({
                'success': False,
                'error': 'ç¼ºå°‘å½“å‰æ•°æ®'
            }), 400
        
        current_data = data['current_data']
        historical_data = data.get('historical_data', [])
        
        # è°ƒç”¨AIå¼‚å¸¸æ£€æµ‹
        result = ai_analyzer.detect_anomaly(current_data, historical_data)
        
        return jsonify({
            'success': result.success,
            'analysis': result.content if result.success else None,
            'provider': result.provider,
            'cost': result.cost,
            'tokens_used': result.tokens_used,
            'response_time': result.response_time,
            'error': result.error_message if not result.success else None,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"å¼‚å¸¸æ£€æµ‹é”™è¯¯: {str(e)}")
        return jsonify({
            'success': False,
            'error': 'æœåŠ¡å†…éƒ¨é”™è¯¯',
            'message': str(e)
        }), 500

@app.route('/api/ai/generate/report', methods=['POST'])
def generate_report():
    """ç”Ÿæˆæ™ºèƒ½æŠ¥å‘Š"""
    try:
        if not ai_analyzer:
            return jsonify({
                'success': False,
                'error': 'AIæœåŠ¡æœªå¯ç”¨æˆ–é…ç½®é”™è¯¯'
            }), 503
            
        data = request.get_json()
        if not data or 'data_summary' not in data:
            return jsonify({
                'success': False,
                'error': 'ç¼ºå°‘æ•°æ®æ‘˜è¦'
            }), 400
        
        data_summary = data['data_summary']
        
        # è°ƒç”¨AIæŠ¥å‘Šç”Ÿæˆ
        result = ai_analyzer.generate_report(data_summary)
        
        return jsonify({
            'success': result.success,
            'report': result.content if result.success else None,
            'provider': result.provider,
            'cost': result.cost,
            'tokens_used': result.tokens_used,
            'response_time': result.response_time,
            'error': result.error_message if not result.success else None,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"æŠ¥å‘Šç”Ÿæˆé”™è¯¯: {str(e)}")
        return jsonify({
            'success': False,
            'error': 'æœåŠ¡å†…éƒ¨é”™è¯¯',
            'message': str(e)
        }), 500

@app.route('/api/ai/qa', methods=['POST'])
def question_answer():
    """æ™ºèƒ½é—®ç­”"""
    try:
        if not ai_analyzer:
            return jsonify({
                'success': False,
                'error': 'AIæœåŠ¡æœªå¯ç”¨æˆ–é…ç½®é”™è¯¯'
            }), 503
            
        data = request.get_json()
        if not data or 'question' not in data:
            return jsonify({
                'success': False,
                'error': 'ç¼ºå°‘é—®é¢˜å†…å®¹'
            }), 400
        
        question = data['question']
        context_data = data.get('context_data', {})
        
        # è°ƒç”¨AIé—®ç­”
        result = ai_analyzer.answer_question(question, context_data)
        
        return jsonify({
            'success': result.success,
            'answer': result.content if result.success else None,
            'question': question,
            'provider': result.provider,
            'cost': result.cost,
            'tokens_used': result.tokens_used,
            'response_time': result.response_time,
            'error': result.error_message if not result.success else None,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"æ™ºèƒ½é—®ç­”é”™è¯¯: {str(e)}")
        return jsonify({
            'success': False,
            'error': 'æœåŠ¡å†…éƒ¨é”™è¯¯',
            'message': str(e)
        }), 500

@app.route('/api/ai/demo/data', methods=['GET'])
def get_demo_data():
    """è·å–æ¼”ç¤ºæ•°æ®"""
    # ç”Ÿæˆæ¨¡æ‹Ÿçš„ä¼ æ„Ÿå™¨æ•°æ®
    now = datetime.now()
    demo_data = []
    
    for i in range(24):  # 24å°æ—¶æ•°æ®
        timestamp = now - timedelta(hours=i)
        demo_data.append({
            'timestamp': timestamp.isoformat(),
            'sensor_id': 'WL001',
            'water_level': 15.2 + (i * 0.1) + ((-1) ** i * 0.3),  # æ¨¡æ‹Ÿæ³¢åŠ¨
            'temperature': 20.5 + (i * 0.05),
            'flow_rate': 120.0 + (i * 2),
            'quality_score': 0.95 - (i * 0.001)
        })
    
    return jsonify({
        'success': True,
        'data': demo_data,
        'count': len(demo_data),
        'description': '24å°æ—¶æ¨¡æ‹Ÿä¼ æ„Ÿå™¨æ•°æ®'
    })

@app.route('/api/ai/demo/analyze', methods=['GET'])
def demo_analyze():
    """æ¼”ç¤ºAIåˆ†æåŠŸèƒ½ï¼ˆä¸éœ€è¦çœŸå®APIå¯†é’¥ï¼‰"""
    # æ¨¡æ‹ŸAIåˆ†æç»“æœ
    mock_analysis = {
        'trend_analysis': {
            'trend': 'ä¸Šå‡',
            'confidence': 0.85,
            'prediction': 'æœªæ¥3å¤©æ°´ä½å°†ç»§ç»­ä¸Šå‡0.5-0.8ç±³',
            'risk_level': 'ä¸­ç­‰',
            'recommendations': [
                'å»ºè®®åŠ å¼ºç›‘æ§é¢‘ç‡',
                'å‡†å¤‡åº”æ€¥é¢„æ¡ˆ',
                'æ£€æŸ¥æ’æ°´è®¾æ–½'
            ]
        },
        'anomaly_detection': {
            'status': 'æ­£å¸¸',
            'anomaly_score': 0.15,
            'last_anomaly': '2å¤©å‰æ£€æµ‹åˆ°è½»å¾®å¼‚å¸¸',
            'details': 'æ‰€æœ‰æŒ‡æ ‡å‡åœ¨æ­£å¸¸èŒƒå›´å†…'
        }
    }
    
    return jsonify({
        'success': True,
        'demo': True,
        'analysis': mock_analysis,
        'message': 'è¿™æ˜¯æ¼”ç¤ºæ•°æ®ï¼Œå®é™…ä½¿ç”¨éœ€è¦é…ç½®AI APIå¯†é’¥',
        'timestamp': datetime.now().isoformat()
    })

@app.errorhandler(404)
def not_found(error):
    return jsonify({
        'error': 'APIæ¥å£ä¸å­˜åœ¨',
        'message': 'è¯·æ£€æŸ¥è¯·æ±‚è·¯å¾„æ˜¯å¦æ­£ç¡®'
    }), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({
        'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯',
        'message': 'è¯·è”ç³»ç®¡ç†å‘˜'
    }), 500

if __name__ == '__main__':
    print("ğŸš€ å¯åŠ¨AIæ™ºèƒ½åˆ†ææœåŠ¡...")
    print(f"ğŸ“ æœåŠ¡åœ°å€: http://localhost:{config.FLASK_PORT}")
    print("ğŸ“‹ å¯ç”¨æ¥å£:")
    print("  - GET  /                    # æœåŠ¡çŠ¶æ€")
    print("  - GET  /api/ai/status       # AIæœåŠ¡çŠ¶æ€")
    print("  - GET  /api/ai/providers    # æ”¯æŒçš„AIæœåŠ¡å•†")
    print("  - POST /api/ai/analyze/trend # è¶‹åŠ¿åˆ†æ")
    print("  - POST /api/ai/detect/anomaly # å¼‚å¸¸æ£€æµ‹")
    print("  - POST /api/ai/generate/report # æŠ¥å‘Šç”Ÿæˆ")
    print("  - POST /api/ai/qa           # æ™ºèƒ½é—®ç­”")
    print("  - GET  /api/ai/demo/data    # æ¼”ç¤ºæ•°æ®")
    print("  - GET  /api/ai/demo/analyze # æ¼”ç¤ºåˆ†æ")
    print()
    
    # æ˜¾ç¤ºå…è´¹AIæœåŠ¡å•†æ¨è
    print("ğŸ’¡ æ¨èä½¿ç”¨å…è´¹AIæœåŠ¡å•†ï¼ˆæŒ‰å…è´¹é¢åº¦æ’åºï¼‰:")
    for provider, description in get_recommended_provider():
        print(f"   {provider}: {description}")
    print()
    
    # åˆå§‹åŒ–AIæœåŠ¡
    ai_initialized = init_ai_service()
    if ai_initialized:
        current_provider = ai_client.provider.value if ai_client else "æœªçŸ¥"
        print(f"âœ… AIæœåŠ¡å·²å¯ç”¨ï¼Œå½“å‰ä½¿ç”¨: {current_provider}")
    else:
        print("âš ï¸  AIæœåŠ¡æœªå¯ç”¨ï¼Œä»…æä¾›æ¼”ç¤ºåŠŸèƒ½")
        print("ğŸ’¡ è¦å¯ç”¨AIåŠŸèƒ½ï¼Œè¯·:")
        print("   1. å¤åˆ¶ config_example.py ä¸º config.py")
        print("   2. é€‰æ‹©ä¸€ä¸ªå…è´¹AIæœåŠ¡å•†å¹¶å¡«å…¥APIå¯†é’¥:")
        print("      - ç™¾åº¦åƒå¸†: https://cloud.baidu.com/product/wenxinworkshop")
        print("      - é˜¿é‡Œé€šä¹‰: https://dashscope.aliyuncs.com/")
        print("      - æœ¬åœ°æ¨¡å‹: å®‰è£…Ollama (https://ollama.ai/)")
        print("   3. è®¾ç½® AI_ANALYSIS_ENABLED = True")
    
    print()
    print("ğŸŒŸ æœåŠ¡å¯åŠ¨ä¸­...")
    
    # å¯åŠ¨Flaskåº”ç”¨
    app.run(
        host='0.0.0.0',
        port=config.FLASK_PORT,
        debug=config.FLASK_DEBUG
    )
